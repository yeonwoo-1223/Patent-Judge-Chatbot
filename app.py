from flask import Flask, render_template, request, jsonify, url_for
import os
import json
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI
from img_model import initialize_index, search_similar

load_dotenv()

# ğŸ” API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° .envì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜´
api_key = os.getenv("OPENAI_API_KEY")
print(f"DEBUG: Loaded API Key? {'Yes' if api_key else 'No'}")
if not api_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
<<<<<<< HEAD
client = OpenAI(api_key=api_key) 
=======
client = OpenAI(api_key=api_key)
>>>>>>> release/final

app = Flask(__name__)

# â€”â€”â€” ì´ë¯¸ì§€ ìœ ì‚¬ë„ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ â€”â€”â€”
TRAIN_FOLDER = "./static/find_similar_images"
IMG_PATHS, IMG_FEATURES = initialize_index(TRAIN_FOLDER)

# í™ˆí™”ë©´
@app.route('/')
def index():
    return render_template('index.html')

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬
@app.route('/upload_image', methods=['POST'])
def upload_image():
    image = request.files.get('image')
    if not image:
        return jsonify({'error': 'ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨'}), 400

    # 1) ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
    upload_dir = './static/uploads'
    os.makedirs(upload_dir, exist_ok=True)
    filename = image.filename
    input_path = os.path.join(upload_dir, filename)
    image.save(input_path)

    # 2) ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰
    try:
        similar = search_similar(input_path, IMG_PATHS, IMG_FEATURES, top_k=5)
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f"ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}"}), 500

    # 3) ê²°ê³¼ êµ¬ì¡°í™”
    results = []
    for path, score in similar:
        name = os.path.basename(path)
        app_no = os.path.splitext(name)[0]
        url = url_for('static', filename=f"find_similar_images/{name}", _external=False)
        results.append({
            'url': url,
            'application_number': app_no,
            'score': float(f"{score:.4f}")
        })

    # 4) í…ìŠ¤íŠ¸ ê¸°ë°˜ ìš”ì•½ ë©”ì‹œì§€ êµ¬ì„±
    lines = [f"{idx}. ì¶œì›ë²ˆí˜¸ {r['application_number']} | ìœ ì‚¬ë„ {r['score']*100:.2f}%" for idx, r in enumerate(results, start=1)]
    raw_message = "\n".join(lines)

    # 5) GPT í˜¸ì¶œ
    chat_messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì•„ë˜ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ íƒœê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , ì¶œì›ë²ˆí˜¸ì™€ ìœ ì‚¬ë„ ìœ„ì£¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”."
        },
        {
            "role": "user",
            "content": raw_message
        }
    ]
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=chat_messages
        )
        bot_message = resp.choices[0].message.content
        bot_message = f"âœ… '{filename}' ì—…ë¡œë“œ ì™„ë£Œ! ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ë³¼ê²Œìš”.\n\n" + bot_message
    except Exception as e:
        print("â–¶ Chat API ì˜¤ë¥˜:", e)
        bot_message = f"âœ… '{filename}' ì—…ë¡œë“œ ì™„ë£Œ! ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ë³¼ê²Œìš”.\n\n" + raw_message

    # 6) ë°˜í™˜
    return jsonify({
        'answer': bot_message,
        'results': results
    })

# ì§ˆë¬¸ ì²˜ë¦¬
@app.route('/ask_bot', methods=['POST'])
def ask_bot():
    data = request.get_json()
    question = data.get('question', '').strip()

    if not question:
        return jsonify({'error': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'})

    try:
        # FAISS ë¶ˆëŸ¬ì˜¤ê¸°
        faiss_path = "Resources/vector_store_law"
        vector_store = FAISS.load_local(faiss_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)

        # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_store.similarity_search(question, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë²•ë¥  ì‚¬ê±´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒì€ ì°¸ê³ í•  ë¬¸ì„œì…ë‹ˆë‹¤:\n\n{context}"
                    },
                    {
                         "role": "user",
                         "content": f"ì´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n{question}"
                         }

        ]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        answer = response.choices[0].message.content

    except Exception as e:
        return jsonify({'error': f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"})

    return jsonify({'answer': answer})

if __name__ == '__main__': 
    if not os.path.exists('./static/uploads'):
        os.makedirs('./static/uploads')
    app.run(debug=True)
