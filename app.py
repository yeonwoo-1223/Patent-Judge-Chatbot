from flask import Flask, render_template, request, jsonify, url_for
import os
import json
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI
from img_model import initialize_index, search_similar

load_dotenv()

# ğŸ” API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° .envì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜´
api_key = os.getenv("OPENAI_API_KEY")
print(f"DEBUG: Loaded API Key? {'Yes' if api_key else 'No'}")
if not api_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(api_key=api_key) 

app = Flask(__name__)

# â€”â€”â€” ì´ë¯¸ì§€ ìœ ì‚¬ë„ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ â€”â€”â€”
TRAIN_FOLDER = "./static/find_similar_images"
IMG_PATHS, IMG_FEATURES = initialize_index(TRAIN_FOLDER)

# í™ˆí™”ë©´
@app.route('/')
def index():
    return render_template('index.html')

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬
@app.route('/upload_image', methods=['POST'])
def upload_image():
    image = request.files.get('image')
    if not image:
        return jsonify({'error': 'ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨'}), 400

    # 1) ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
    upload_dir = './static/uploads'
    os.makedirs(upload_dir, exist_ok=True)
    filename = image.filename
    input_path = os.path.join(upload_dir, filename)
    image.save(input_path)

    # 2) ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰
    try:
        similar = search_similar(input_path, IMG_PATHS, IMG_FEATURES, top_k=5)
    except Exception as e:
        import traceback
        traceback.print_exc()   # í„°ë¯¸ë„ì— ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
        # í´ë¼ì´ì–¸íŠ¸ì—ë„ ì˜¤ë¥˜ ë©”ì‹œì§€ ë‚´ë ¤ì¤ë‹ˆë‹¤.
        return jsonify({'error': f"ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}"}), 500

    # 3) ê²°ê³¼ë¥¼ URL, ì¶œì›ë²ˆí˜¸, ìœ ì‚¬ë„ í˜•íƒœë¡œ êµ¬ì¡°í™”
    results = []
    for path, score in similar:
        name = os.path.basename(path)
        app_no = os.path.splitext(name)[0]
        url = url_for('static', filename=f"find_similar_images/{name}", _external=False)
        results.append({
            'url': url,
            'application_number': app_no,
            'score': float(f"{score:.4f}")
        })

    # 4) ì±—ë´‡ ë§íˆ¬ìš© ìš”ì•½ ë©”ì‹œì§€(raw)
    lines = [f"âœ… '{filename}' ì—…ë¡œë“œ ì™„ë£Œ! ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ë³¼ê²Œìš”."]
    for idx, r in enumerate(results, start=1):
        lines.append(f"{idx}. ì¶œì›ë²ˆí˜¸ {r['application_number']} | ìœ ì‚¬ë„ {r['score']*100:.2f}%")
    raw_message = "\n".join(lines)

    # 5) OpenAI Chat API í˜¸ì¶œ â†’ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ê°€ê³µ
    chat_messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ íƒœê·¸(![ì¶œì›ë²ˆí˜¸](URL))ë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ê°€ ë°”ë¡œ ë³´ì´ë„ë¡ ì„¤ëª…í•´ì£¼ì„¸ìš”. ê° í•­ëª©ì— ì¶œì›ë²ˆí˜¸ì™€ ìœ ì‚¬ë„ë„ í•¨ê»˜ í¬í•¨í•˜ì„¸ìš”."},
        {"role": "user",   "content": raw_message}
    ]
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=chat_messages
        )
        bot_message = resp.choices[0].message.content
    except Exception as e:
        # RateLimitError ë˜ëŠ” ê¸°íƒ€ ëª¨ë“  ì˜¤ë¥˜ ì‹œì—ë„ raw_message ë¡œ graceful fallback
        print("â–¶ Chat API ì˜¤ë¥˜:", e)
        bot_message = raw_message

    # 6) JSON ë°˜í™˜ (ë§í’ì„  í…ìŠ¤íŠ¸ + êµ¬ì¡°í™”ëœ ê²°ê³¼)
    return jsonify({
        'answer': bot_message,
        'results': results
    })

# ì§ˆë¬¸ ì²˜ë¦¬ ë° GPT í˜¸ì¶œ (ë¹„ë™ê¸° JSON ë°˜í™˜)
@app.route('/ask_bot', methods=['POST'])
def ask_bot():
    data = request.get_json()
    question = data.get('question', '').strip()

    if not question:
        return jsonify({'error': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'})

    try:
        #FAISS ë¡œë“œ
        faiss_path = "Resources/vector_store_law" # ê²½ë¡œ í™•ì¸
        vector_store = FAISS.load_local(faiss_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)

        #ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_store.similarity_search(question, k=3)  # ìƒìœ„ 3ê°œ ë¬¸ì„œ

        #context êµ¬ì„±
        context = "\n\n".join([doc.page_content for doc in docs])

        #GPT ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë²•ë¥  ì‚¬ê±´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒì€ ì°¸ê³ í•  ë¬¸ì„œì…ë‹ˆë‹¤:\n\n{context}"
                    },
                    {
                         "role": "user",
                         "content": f"ì´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n{question}"
                         }
        ]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        answer = response.choices[0].message.content

    except Exception as e:
        return jsonify({'error': f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"})

    return jsonify({'answer': answer})

if __name__ == '__main__':
    if not os.path.exists('./static/uploads'):
        os.makedirs('./static/uploads')
    app.run(debug=True)
