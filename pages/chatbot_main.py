import streamlit as st
from Modules.ModuleImport import *  # ëª¨ë“  ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
from Modules.VectorStore import *
load_dotenv()
from Modules.prompt import contextual_prompt
from Modules.prompt import translate_template1
from Modules.prompt import summary_prompt
from Modules.prompt import image_prompt_template
from Modules.ContextToPrompt import ContextToPrompt
from Modules.RetrieverWrapper import RetrieverWrapper
import Modules.Speech as Speech

def chatbot_main():
    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])
    now_dir = os.getcwd()
    translate_model = ChatOpenAI(model="gpt-4o-mini")

    # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ ì„¤ì •
    st.markdown(
        """
        <style>
            div[data-testid="stSidebarUserContent"] .stButton button div {
                max-height: 24px;
                overflow-y: hidden;
            }
            .stMainBlockContainer .stButton button {
                font-size: 20px;
                color: white;
                background-color: rgb(255, 75, 75);
                padding: 10px 20px;
                border: none;
                border-radius: 5px;
                cursor: pointer;
                z-index: 10000;
            }
            .stMainBlockContainer .stButton button[data-testid="stBaseButton-primary"] {
                position: fixed;
                padding: 1px 10px;
                bottom: 50px;
                left: 550px;
            }
            .stMainBlockContainer .stButton button[data-testid="stBaseButton-primary"] p {
                font-size: 32px;
            }
        </style>
        """,
        unsafe_allow_html=True,
    )
    placeholder = st.empty()

    def find_most_similar_doc(user_accident):
        """
        ì‚¬ìš©ìê°€ ì œê³µí•œ ì‚¬ê³  ì •ë³´ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ FAISS ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        Args:
            user_accident (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì‚¬ê³  ìƒí™© í…ìŠ¤íŠ¸.
            vector_store (FAISS): FAISS ë²¡í„° ìŠ¤í† ì–´ ê°ì²´.
            embeddings (OpenAIEmbeddings): ì„ë² ë”© ëª¨ë¸ ê°ì²´.

        Returns:
            dict: ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œì˜ ì •ë³´ (í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°).
        """
        # ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ê³„ì‚°
        query_embedding = embeddings.embed_query(user_accident)

        # ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        search_results = vector_store_rate.similarity_search_by_vector(
            query_embedding, k=1)

        # ê²°ê³¼ ë°˜í™˜ (ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 1ê°œ)
        if search_results:
            return search_results[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        else:
            return None  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°

    def init():
        # ëŒ€í™”ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë°ì´í„° ì´ˆê¸°í™”
        if os.path.isdir(now_dir + "/History"):
            prompt_file = os.listdir(now_dir + "/History")

            prompt_file = sorted(prompt_file, key=lambda x: int(x.split('.')[0].replace("history", "")), reverse=True)

            if len(prompt_file) > 0 and len(st.session_state.side_data) == 0:
                for file in prompt_file:
                    with open(now_dir + "/History/" + file, 'r', encoding='UTF8') as f:
                        json_data = json.load(f)
                        side_title = json_data[0]["content"][0:10]
                        st.session_state.side_data.append({side_title:file})
    init()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title('ì±„íŒ… ë‚´ì—­')
        # ëŒ€í™”ë°© ì¶”ê°€
        if st.button("ìƒˆë¡œìš´ ë°©", type="primary"):
            st.session_state["messages"] = []
            st.session_state["active"] = ""

        sidebar_placeholder = st.sidebar.empty() # ì‚¬ì´ë“œë°”ì— ë‹¤ë¥¸ ìš”ì†Œ ì¶”ê°€ì‹œí‚¤ê¸° ìœ„í•¨        
        for i, room in enumerate(st.session_state["side_data"]):
            for room_name, file_name in room.items():
                cols = st.columns([4, 1])  # ë²„íŠ¼ê³¼ ì‘ì—… ë²„íŠ¼ì„ ë‚˜ëˆ„ê¸° ìœ„í•´ ì»¬ëŸ¼ ì‚¬ìš©
                with cols[0]:
                    # type - ì„ íƒëœ ë²„íŠ¼ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ í‘œì‹œ (ë³´ë¥˜)
                    if st.button(room_name, key=f"{room_name}_{file_name}{i}"):  # ê° ëŒ€í™”ë°© ì´ë¦„ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥
                        st.session_state["messages"] = []
                        st.session_state["active"] = file_name
                        with placeholder.container():
                            with open(os.path.join(now_dir, "History", file_name), 'r', encoding='UTF8') as f:
                                json_data = json.load(f)
                                for message in json_data:
                                    st.session_state["messages"].append({"role":message["role"], "content":message["content"]})
                                    with st.chat_message(message["role"]):
                                        st.write(message["content"])
                with cols[1]:
                    if st.button("ğŸ—‘ï¸", key=f"delete_{room_name}_{i}"):
                        # ì‚­ì œ ë¡œì§
                        file_path = os.path.join("History", file_name)
                        if os.path.exists(file_path):
                            os.remove(file_path)
                        del st.session_state["side_data"][i]

                        if file_name == st.session_state["active"]:
                            st.session_state["messages"] = []
                            st.session_state["active"] = ""

                        st.session_state["rerun"] = True

    if st.session_state["rerun"]:
        print("rerun")
        st.session_state["rerun"] = False
        st.rerun()

    # ì±„íŒ… ë‚´ì—­ session_state ì €ì¥
    def session_save(data):
        now_dir = os.getcwd()
        history_dir = now_dir + "/History/"
        # History í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if os.path.isdir(history_dir):
            prompt_file = os.listdir(history_dir)

            # ë§ˆì§€ë§‰ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë„˜ë²„ë§
            sorted_file_list = natsort.natsorted(prompt_file)
            if len(sorted_file_list) > 0:
                last_file = sorted_file_list[len(sorted_file_list)-1].split(".")[0]
                file_cnt = int(last_file.replace("history", "")) + 1
            else:
                file_cnt = 1

            file_name = "history" + str(file_cnt) + ".json"

            active = st.session_state.active
            active_file = now_dir + "/History/" + active 

            # ì²« ì§ˆë¬¸ - active ê°’ ì—†ìŒ - dumpë¡œ ìƒì„±
            if active == "":
                with open(history_dir + file_name, 'w', encoding='UTF8') as f:
                    json.dump([data], f)

                    room_name = data["content"][0:10]
                    st.session_state["active"] = file_name
                    st.session_state.side_data.insert(0,{room_name:file_name})
                    
                    with sidebar_placeholder.container():
                        button_key = f"{room_name}_{file_name}{len(st.session_state.side_data)}"  
                        # ë™ì ìœ¼ë¡œ ë²„íŠ¼ ì¶”ê°€ì‹œ - í´ë¦­ì´ë²¤íŠ¸ ë¹„ì •ìƒ ì‘ë™ - (ë³´ë¥˜)
                        if st.button(room_name, key=button_key):  # ê° ëŒ€í™”ë°© ì´ë¦„ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥
                            st.session_state["rerun"] = True
                            print("new btn")
            # ë‘ë²ˆì§¸ëŠ” - session_state ê°’ ìˆìŒ - update
            elif os.path.isfile(active_file):
                with open(active_file, 'r', encoding='UTF8') as f:
                    try:
                        # ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
                        json_data = json.load(f)
                        if not isinstance(json_data, list):
                            json_data = []  # íŒŒì¼ì— ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
                    except json.JSONDecodeError:
                        json_data = []  # íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ˆê¸°í™”
                        
                    json_data.append(data)

                # vector DB ì—…ë°ì´íŠ¸
                if data["role"] == "assistant" and st.session_state["messages"]:
                    question = st.session_state["messages"][-2]["content"]
                    answer = data["content"]
                    update_vector_db(question, answer)

                with open(active_file, 'w', encoding='UTF8') as f:
                    json.dump(json_data, f)

    # ì–¸ì–´ ê°ì§€ í•¨ìˆ˜
    def detect_language(query):
        try:
            return detect(query)  # ì •ìƒì ìœ¼ë¡œ ì–¸ì–´ ê°ì§€
        except LangDetectException:
            return "ko"  # ì‹¤íŒ¨ ì‹œ "ko" ë°˜í™˜

    def make_rag_chain(query):
            # RAG ì²´ì¸ ì •ì˜
        rag_chain_debug = {
            "context": RetrieverWrapper(retriever),
            "context1": RetrieverWrapper(retriever1),
            'context2': RetrieverWrapper(retriever2),
        }

        # ë²ˆì—­ ë° query ë³€í™˜
        query_text = translate_chain1.invoke({"language": detect_language(query), "text": query})
        query_text = query_text.content if hasattr(query_text, "content") else query_text

        # 1. ê²€ìƒ‰ ë‹¨ê³„: context, context1, context2ë¡œë¶€í„° ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
        response_docs = rag_chain_debug["context"].invoke({"question": query_text})
        response_docs1 = rag_chain_debug["context1"].invoke({"question": query_text})
        response_docs2 = find_most_similar_doc(response_docs1[0].metadata['summary'].content)

        # 'contextual_prompt'ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        prompt_messages = contextual_prompt.format_messages(
            context=response_docs,  # ê²€ìƒ‰ëœ context ë°ì´í„°
            context1=response_docs1,  # ê²€ìƒ‰ëœ context1 ë°ì´í„°
            context2=response_docs2,  # ê²€ìƒ‰ëœ context2 ë°ì´í„°
            question=query_text,  # ì‚¬ìš©ìì˜ ì§ˆë¬¸
            language=detect_language(query)  
        )
        return prompt_messages

    # ì‚¬ê³  ìƒí™©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜ (LLM ëª¨ë¸ ì‚¬ìš©)
    def summarize_accident(accident_text):
        summary = summary_prompt.format_messages(content=accident_text)
        result = translate_model.invoke(summary)
        return result  # ìš”ì•½ëœ ì‚¬ê³  ìƒí™© ë°˜í™˜

    # ì‚¬ìš©ì ì…ë ¥ -> ëª¨ë¸
    translate_chain1 = translate_template1 | translate_model


    # ì„¸ì…˜ ë°ì´í„°ë¥¼ ë²¡í„° DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    def update_vector_db(question, answer):
        """
        ì‚¬ìš©ì ì§ˆì˜ì™€ ì‘ë‹µ ë°ì´í„°ë¥¼ ë²¡í„° DBì— ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ìì—´ì„ ì •ìƒì ì¸ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©
        decoded_question = bytes(question, 'utf-8').decode('unicode_escape')
        decoded_answer = bytes(answer, 'utf-8').decode('unicode_escape')

        # ì™¸êµ­ì–´ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš° ë²ˆì—­ ì§„í–‰
        decoded_question = translate_chain1.invoke(
            {"language": detect_language(decoded_question), "text": question})
        decoded_question = decoded_question.content if hasattr(
            decoded_question, "content") else decoded_question
        decoded_answer = translate_chain1.invoke(
            {"language": detect_language(decoded_answer), "text": answer})
        decoded_answer = decoded_answer.content if hasattr(
            decoded_answer, "content") else decoded_answer

        # ì‚¬ìš©ì ì…ë ¥ ì‚¬ê³  ë‚´ìš© ìš”ì•½
        summarize_quesetion = summarize_accident(decoded_question)

        # ë””ì½”ë”©ëœ ì§ˆë¬¸ê³¼ ì‘ë‹µì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        combined_text = f"ì§ˆë¬¸: {summarize_quesetion}\nì‘ë‹µ: {decoded_answer}"

        # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”
        new_embedding = embeddings.embed_query(combined_text)

        # ìƒˆë¡œìš´ ë²¡í„°ë¥¼ FAISS DBì— ì¶”ê°€
        vector_store_rate.add_texts([combined_text], embeddings=[new_embedding])
        vector_store_rate.save_local('vector_store_rate')

    def chatbot(query, isType):
        print(f"íŠ¹í—ˆ ì±—ë´‡ í…ìŠ¤íŠ¸ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ : ",st.session_state["messages"])
        # ê¸°ë³¸ ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
        for message in st.session_state["messages"]:
            with st.chat_message(message["role"]):
                st.write(message["content"])

        data = {"role": "user", "content": query}
        st.session_state.messages.append(data)
        session_save(data)

        with st.chat_message("user"):  # ì‚¬ìš©ì ì±„íŒ… í‘œì‹œ
            st.write(query)
            chain_response = make_rag_chain(query)

        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶œë ¥
        with st.chat_message("assistant"):
            # ìŠ¤íŠ¸ë¦¼ ìƒì„±
            stream = client.chat.completions.create(
                model=st.session_state["openai_model"],
                messages=[
                    *[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    *[
                        {"role": "system", "content": chain_response[0].content},
                        {"role": "user", "content": chain_response[1].content},
                    ],
                ],
                stream=True,
            )
            response = st.write_stream(stream)

            data = {"role":"assistant", "content":response}
            st.session_state.messages.append(data)
            session_save(data)

            if isType == 'voice':     # voice íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ì½ê¸°
                Speech.text_to_speech(response)

    if st.button(":material/mic:", type="primary"):             # ë§ˆì´í¬ ì…ë ¥ì‹œ ë³´ì´ìŠ¤ ì¬ìƒ
        user_input = Speech.get_audio_input()
        if user_input is not None:
            chatbot(user_input, 'voice')

    query = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", key="fixed_chat_input")
    if query:
        chatbot(query, 'text')